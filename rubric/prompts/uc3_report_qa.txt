TASK: Evaluate a report-based Q&A output.

The AI was asked to answer a question based on the following report/source material.

SOURCE MATERIAL:
{{source_text}}

QUESTION/INSTRUCTION:
{{instruction}}

{{#reference_output}}
REFERENCE ANSWER (for comparison):
{{reference_output}}
{{/reference_output}}

AI-GENERATED ANSWER:
{{generated_text}}

Evaluate this answer on each criterion below. For each criterion, assign an integer score from 1 to 5.
You may use intermediate scores (2 or 4) if the quality falls between the defined anchors (1, 3, 5).
Provide specific reasoning for your score.

{{criteria_block}}

Respond with a JSON object containing:
- "request_id": "{{request_id}}"
- "judge_model": your model name
- "scores": array of {"criterion", "score", "reasoning"} for each criterion
- "overall": {"weighted_score", "pass", "conciseness_penalty_applied"}
- "format_valid": true
